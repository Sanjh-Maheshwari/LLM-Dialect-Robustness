{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k24053411/.conda/envs/fever/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import warnings\n",
    "from datasets import load_dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_leaving_out(dictionary, key):\n",
    "    copy = dictionary.copy()\n",
    "    del copy[key]\n",
    "    return copy\n",
    "\n",
    "def process_data(dataset): \n",
    "    \n",
    "    processed_data = {}\n",
    "    \n",
    "    for data in dataset:\n",
    "        task = data[\"task\"]\n",
    "\n",
    "        data_filtered = copy_leaving_out(data, \"task\")\n",
    "\n",
    "        if task in processed_data.keys():\n",
    "            processed_data[task].append(data_filtered)\n",
    "        else:\n",
    "            processed_data[task] = [data_filtered]\n",
    "            \n",
    "    for task in processed_data.keys():\n",
    "\n",
    "        source_dict = {}\n",
    "        dataset = processed_data[task]\n",
    "        \n",
    "        for data in dataset:\n",
    "            source = data[\"source\"]\n",
    "\n",
    "            data_filtered = copy_leaving_out(data, \"source\")\n",
    "\n",
    "            if source in source_dict.keys():\n",
    "                source_dict[source].append(data_filtered)\n",
    "            else:\n",
    "                source_dict[source] = [data_filtered]\n",
    "        \n",
    "        processed_data[task] = source_dict\n",
    "        \n",
    "    for task in processed_data.keys():\n",
    "\n",
    "        source_dict = processed_data[task]\n",
    "\n",
    "        for source in source_dict.keys():\n",
    "            \n",
    "            variety_dict = {}\n",
    "            dataset = source_dict[source]\n",
    "            \n",
    "            for data in dataset:\n",
    "                variety = data[\"variety\"]\n",
    "\n",
    "                data_filtered = copy_leaving_out(data, \"variety\")\n",
    "\n",
    "                if variety in variety_dict.keys():\n",
    "                    variety_dict[variety].append(data_filtered)\n",
    "                else:\n",
    "                    variety_dict[variety] = [data_filtered]\n",
    "            \n",
    "            source_dict[source] = variety_dict\n",
    "        \n",
    "        processed_data[task] = source_dict\n",
    "        \n",
    "    print('Sanity Check : ', len(processed_data['Sentiment']['Google'][\"en-UK\"]))\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Besstie dataset from Hugging Face...\n",
      "Loaded Dolly dataset with 2428 total samples\n",
      "Dataset columns: ['text', 'label', 'variety', 'source', 'task']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Besstie dataset from Hugging Face...\")\n",
    "dataset_train = load_dataset(\"unswnlporg/BESSTIE\", split =  \"train\")\n",
    "dataset_test = load_dataset(\"unswnlporg/BESSTIE\", split =  \"validation\")\n",
    "\n",
    "print(f\"Loaded BESSTIE dataset with {len(dataset_train)} (train) and {len(dataset_test)} (test) total samples\")\n",
    "print(f\"Dataset columns: {list(dataset_train.features.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"Ordered red hot fried and hot honey fried. The taste is good for a fried chicken. The sauce is not coated evenly., but that's okay I guess. The size is big, that's good.\",\n",
       "  'I wish we had found this place for lunch, but instead, we tried one of the other places but stopped here for Bingsu. From what we did see, the food looks like a winner here, so I will be back to try on the next trip. Serving was decent and a great concept for a restaurant with various Asian Cuisine options.',\n",
       "  \"If you're in the mood for a culinary adventure, look no further than Starfish. Nestled alongside a picturesque riverside patio, this gem of a bistro offers an exquisite selection of seafood and wood-fired pizza that will leave your taste buds dancing with delight. The standout for me was the delectable Thai Chicken Pizza. The harmonious blend of zesty Thai flavors with succulent chicken and perfectly baked crust was nothing short of a taste revelation. It's a bold fusion that pays off in spades-a must-try for any pizza enthusiast. Equally impressive were the Curly Fries. Golden and crispy on the outside, with just the right amount of seasoning, they were a delightful accompaniment to our meal. These fries elevated the experience, adding an extra layer of satisfaction.\",\n",
       "  'First time at a Hogs Breath restaurant and was very happy with my food. I had the Steak with curly fries & mac n cheese. The steak was cooked perfectly and the fries were delicious with the gravy. Only down side is the mac n cheese was cold and the fries were nt very warm.',\n",
       "  'I honestly love eating the food here its my favourite go to Chinese for Kalgoorlie. I kinda miss the chow mein thou not a fan of the thick egg noodles but it will do. Lemon Chicken and Fried Rice are my fave!!!! The lady that does nights is so lovely.'],\n",
       " 'label': [1, 1, 1, 1, 1],\n",
       " 'variety': ['en-AU', 'en-AU', 'en-AU', 'en-AU', 'en-AU'],\n",
       " 'source': ['Google', 'Google', 'Google', 'Google', 'Google'],\n",
       " 'task': ['Sentiment', 'Sentiment', 'Sentiment', 'Sentiment', 'Sentiment']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_data(dataset_train)\n",
    "\n",
    "with open('../data/instruction/besstie/train.json', 'w') as f:\n",
    "    json.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_data(dataset_test)\n",
    "\n",
    "with open('../data/instruction/besstie/test.json', 'w') as f:\n",
    "    json.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
